{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer Testing Matrix\n",
    "\n",
    "**Purpose**: Systematically compare portfolio optimization strategies under consistent market conditions.\n",
    "\n",
    "This notebook implements the testing matrix from `/docs/Portfolio_Weight_Optimization.md`.\n",
    "\n",
    "## Available Optimizers:\n",
    "1. **Equal Weight** - Simple benchmark\n",
    "2. **Score-Weighted** - Weights proportional to ML scores\n",
    "3. **Inverse Volatility** - Risk parity balance\n",
    "4. **MVO** - Mean-variance optimization (max Sharpe)\n",
    "5. **MVO_REG** - Regularized MVO with L2 penalty\n",
    "6. **HRP** - Hierarchical Risk Parity\n",
    "7. **Hybrid** - Combine scores + risk\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import sys\n",
    "import os\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Add project root to path\n",
    "project_root = os.path.abspath('..')\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "print(f\"Working directory: {os.getcwd()}\")\n",
    "print(f\"Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "config_path = os.path.join(project_root, 'config/config.yaml')\n",
    "with open(config_path) as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(\"âœ“ Configuration loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import project modules\n",
    "from src.io.ingest_ohlcv import OHLCVIngester\n",
    "from src.features.ta_features import create_technical_features\n",
    "from src.labeling.labels import generate_forward_returns\n",
    "from src.ml.dataset import MLDataset, create_time_based_split\n",
    "from src.ml.train import ModelTrainer\n",
    "from src.portfolio.optimizer_comparison import (\n",
    "    run_optimizer_comparison,\n",
    "    generate_optimizer_recommendations\n",
    ")\n",
    "\n",
    "print(\"âœ“ Modules imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Load Pre-computed Features & Scores\n",
    "\n",
    "**Option 1**: Use existing data from `01_interactive_pipeline.ipynb`  \n",
    "**Option 2**: Generate new data (uncomment cells below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-computed features from previous run\n",
    "try:\n",
    "    df = pd.read_parquet('data/features/all_features.parquet')\n",
    "    print(f\"âœ“ Loaded {len(df):,} rows of features\")\n",
    "    print(f\"Date range: {df['date'].min()} to {df['date'].max()}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"âš ï¸ Features file not found. Please run 01_interactive_pipeline.ipynb first.\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate ML Scores\n",
    "\n",
    "Train model and generate predictions (or load existing model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-based split\n",
    "label_col = f\"forward_return_{config['labels']['horizon']}d\"\n",
    "train_df, test_df = create_time_based_split(df, test_size=0.2, embargo_days=5)\n",
    "\n",
    "print(f\"Train: {len(train_df):,} rows ({train_df['date'].min()} to {train_df['date'].max()})\")\n",
    "print(f\"Test:  {len(test_df):,} rows ({test_df['date'].min()} to {test_df['date'].max()})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare ML dataset\n",
    "dataset = MLDataset(label_col=label_col)\n",
    "X_train, y_train = dataset.prepare(train_df, auto_select_features=True)\n",
    "X_test, y_test = dataset.prepare(test_df, auto_select_features=False)\n",
    "\n",
    "print(f\"Training set: {len(X_train):,} samples, {len(X_train.columns)} features\")\n",
    "print(f\"Test set:     {len(X_test):,} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model (or load existing)\n",
    "trainer = ModelTrainer(config)\n",
    "\n",
    "# Option 1: Train new model\n",
    "trainer.train(X_train, y_train)\n",
    "print(\"âœ“ Model trained\")\n",
    "\n",
    "# Option 2: Load existing model\n",
    "# trainer.load_model('data/models/latest_model.pkl')\n",
    "# print(\"âœ“ Model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate ML scores for test period\n",
    "X_test_full, _ = dataset.prepare(test_df, auto_select_features=False)\n",
    "scores = trainer.predict(X_test_full)\n",
    "\n",
    "# Create scored DataFrame\n",
    "test_df_clean = test_df[test_df[label_col].notna()].copy()\n",
    "scored_df = test_df_clean[['date', 'symbol']].copy()\n",
    "scored_df['ml_score'] = scores\n",
    "\n",
    "print(f\"âœ“ Generated scores for {len(scored_df):,} observations\")\n",
    "print(f\"\\nScore statistics:\")\n",
    "print(scored_df['ml_score'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get price panel\n",
    "price_panel = df[['date', 'symbol', 'close']].copy()\n",
    "print(f\"âœ“ Price panel: {len(price_panel):,} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Run Optimizer Comparison\n",
    "\n",
    "This will test all optimizers on the same data and generate comparative metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizers to test\n",
    "optimizers_to_test = [\n",
    "    'equal',\n",
    "    'score_weighted',\n",
    "    'inv_vol',\n",
    "    'mvo',\n",
    "    'hybrid',\n",
    "    # 'hrp',  # Uncomment if you want to test HRP (may be slower)\n",
    "]\n",
    "\n",
    "print(f\"Testing {len(optimizers_to_test)} optimizers: {optimizers_to_test}\")\n",
    "print(\"\\nThis may take 2-5 minutes depending on data size...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run comparison\n",
    "comparison_results = run_optimizer_comparison(\n",
    "    scored_df=scored_df,\n",
    "    price_panel=price_panel,\n",
    "    config=config,\n",
    "    optimizers=optimizers_to_test,\n",
    "    score_col='ml_score'\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"âœ“ Comparison complete!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display full results table\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"OPTIMIZER COMPARISON - DETAILED RESULTS\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "display_df = comparison_results[[\n",
    "    'optimizer', 'sharpe_ratio', 'annual_return', 'volatility',\n",
    "    'max_drawdown', 'avg_turnover', 'hhi', 'effective_n'\n",
    "]].copy()\n",
    "\n",
    "# Format for display\n",
    "display_df['annual_return'] = display_df['annual_return'].apply(lambda x: f\"{x:.2%}\")\n",
    "display_df['volatility'] = display_df['volatility'].apply(lambda x: f\"{x:.2%}\")\n",
    "display_df['max_drawdown'] = display_df['max_drawdown'].apply(lambda x: f\"{x:.2%}\")\n",
    "display_df['avg_turnover'] = display_df['avg_turnover'].apply(lambda x: f\"{x:.2%}\")\n",
    "display_df['sharpe_ratio'] = display_df['sharpe_ratio'].apply(lambda x: f\"{x:.2f}\")\n",
    "display_df['hhi'] = display_df['hhi'].apply(lambda x: f\"{x:.4f}\")\n",
    "display_df['effective_n'] = display_df['effective_n'].apply(lambda x: f\"{x:.1f}\")\n",
    "\n",
    "print(display_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate recommendations\n",
    "recommendations = generate_optimizer_recommendations(comparison_results)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"OPTIMIZER RECOMMENDATIONS\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "for objective, recommendation in recommendations.items():\n",
    "    print(f\"ðŸŽ¯ {objective.replace('_', ' ').title()}:\")\n",
    "    print(f\"   â†’ {recommendation}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance comparison charts\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Sharpe Ratio\n",
    "comparison_results_sorted = comparison_results.sort_values('sharpe_ratio', ascending=False)\n",
    "axes[0, 0].barh(comparison_results_sorted['optimizer'], comparison_results_sorted['sharpe_ratio'])\n",
    "axes[0, 0].set_xlabel('Sharpe Ratio')\n",
    "axes[0, 0].set_title('Risk-Adjusted Performance', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Return vs Volatility\n",
    "axes[0, 1].scatter(\n",
    "    comparison_results['volatility'] * 100,\n",
    "    comparison_results['annual_return'] * 100,\n",
    "    s=200,\n",
    "    alpha=0.6\n",
    ")\n",
    "for _, row in comparison_results.iterrows():\n",
    "    axes[0, 1].annotate(\n",
    "        row['optimizer'],\n",
    "        (row['volatility'] * 100, row['annual_return'] * 100),\n",
    "        fontsize=9\n",
    "    )\n",
    "axes[0, 1].set_xlabel('Volatility (%)')\n",
    "axes[0, 1].set_ylabel('Annual Return (%)')\n",
    "axes[0, 1].set_title('Return vs Risk Profile', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Max Drawdown\n",
    "comparison_results_sorted_dd = comparison_results.sort_values('max_drawdown', ascending=False)\n",
    "axes[1, 0].barh(comparison_results_sorted_dd['optimizer'], comparison_results_sorted_dd['max_drawdown'] * 100)\n",
    "axes[1, 0].set_xlabel('Max Drawdown (%)')\n",
    "axes[1, 0].set_title('Downside Risk', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Concentration (HHI)\n",
    "comparison_results_sorted_hhi = comparison_results.sort_values('hhi')\n",
    "axes[1, 1].barh(comparison_results_sorted_hhi['optimizer'], comparison_results_sorted_hhi['hhi'])\n",
    "axes[1, 1].set_xlabel('Herfindahl Index (Lower = More Diversified)')\n",
    "axes[1, 1].set_title('Portfolio Concentration', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turnover vs Sharpe trade-off\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "\n",
    "scatter = ax.scatter(\n",
    "    comparison_results['avg_turnover'] * 100,\n",
    "    comparison_results['sharpe_ratio'],\n",
    "    s=300,\n",
    "    c=comparison_results['hhi'],\n",
    "    cmap='viridis',\n",
    "    alpha=0.7\n",
    ")\n",
    "\n",
    "for _, row in comparison_results.iterrows():\n",
    "    ax.annotate(\n",
    "        row['optimizer'],\n",
    "        (row['avg_turnover'] * 100, row['sharpe_ratio']),\n",
    "        fontsize=10,\n",
    "        ha='center'\n",
    "    )\n",
    "\n",
    "ax.set_xlabel('Average Turnover (%)', fontsize=12)\n",
    "ax.set_ylabel('Sharpe Ratio', fontsize=12)\n",
    "ax.set_title('Turnover vs Performance Trade-off\\n(Color = Concentration)', \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Add colorbar\n",
    "cbar = plt.colorbar(scatter, ax=ax)\n",
    "cbar.set_label('HHI (Concentration)', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Interpretation Framework\n",
    "\n",
    "Based on the results, consider the following:\n",
    "\n",
    "| Observation | Interpretation | Action |\n",
    "|-------------|----------------|--------|\n",
    "| High Sharpe + Low Drawdown | Efficient allocation | Prioritize for production |\n",
    "| High Turnover + Same Sharpe | Overfitting or excessive rebalancing | Increase rebalance interval |\n",
    "| HRP > MVO Stability | Covariance estimation too noisy | Use shrinkage or HRP |\n",
    "| Hybrid Outperforms | ML scores add predictive alpha | Keep hybrid weighting as default |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save comparison results\n",
    "output_path = 'data/reports/optimizer_comparison.csv'\n",
    "comparison_results.to_csv(output_path, index=False)\n",
    "print(f\"âœ“ Results saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Next Steps\n",
    "\n",
    "1. **Select Best Optimizer**: Update `config.yaml` with the best-performing optimizer\n",
    "2. **Fine-tune Parameters**: Adjust optimizer-specific settings (e.g., hybrid weights, HRP linkage)\n",
    "3. **Test Different Regimes**: Run comparison on different market periods\n",
    "4. **Production Deployment**: Use selected optimizer in live trading system\n",
    "\n",
    "**To change optimizer in config:**\n",
    "```yaml\n",
    "portfolio:\n",
    "  optimizer: \"hybrid\"  # Change to your preferred optimizer\n",
    "```\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "us-stock-app",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
